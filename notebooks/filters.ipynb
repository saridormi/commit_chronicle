{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# #1: Filters implementations\n",
    "\n",
    "In this section, we discuss the frequent filters from CMG datasets and provide our implementations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First sentence filter\n",
    "\n",
    "Most works don't actually filter out the examples with more than one sentence, rather extract the first sentence from each commit message. But we're still interested to check how many examples this processing affects."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are two options:\n",
    "\n",
    "* `newline`: some works extracted the first sentence based on the newline character `\\n`;\n",
    "* `punct`: some works extracted the first sentence based on trailing punctuation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "\n",
    "def is_one_sentence(text: str, mode: Literal[\"newline\", \"punct\"], nl_char: str = \"\\n\") -> bool:\n",
    "    \"\"\"Implements single sentence filter.\n",
    "\n",
    "    Args:\n",
    "        text: Input string.\n",
    "        mode: Sentence splitting logic.\n",
    "\n",
    "    Returns:\n",
    "        True if text only has one sentence, False otherwise.\n",
    "\n",
    "    Notes:\n",
    "        There are two modes:\n",
    "        * `newline` simply splits sentences by newline character\n",
    "        * `punct` relies on PunktSentenceTokenizer from nltk\n",
    "    \"\"\"\n",
    "    if mode == \"newline\":\n",
    "        lines = text.split(nl_char)\n",
    "        return len(lines) == 1\n",
    "    elif mode == \"punct\":\n",
    "        try:\n",
    "            lines = sent_tokenize(text)\n",
    "        except IndexError:\n",
    "            return None\n",
    "        return len(lines) == 1\n",
    "\n",
    "    raise ValueError(\"Unknown configuration\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Verb-Direct Object (V-DO) filter\n",
    "\n",
    "This filter targets grammatical structure of commit messages: it only allows commit messages that start with Verb-Direct Object clause. It was proposed in [Automatically Generating Commit Messages from Diffs using Neural Machine Translation](https://arxiv.org/abs/1708.09492), ASE 2017, and originally implemented via [CoreNLP](https://github.com/stanfordnlp/CoreNLP) Java package."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### spaCy implementation\n",
    "\n",
    "We reimplemented V-DO filter via [spaCy](https://github.com/explosion/spaCy) – popular Python library for Natural Language Processing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:36:37.000510Z",
     "end_time": "2023-04-18T17:36:38.747258Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def is_verb_direct_object(text: str):\n",
    "    \"\"\"Implements filter by Verb-Direct Object grammar structure via spaCy package.\n",
    "\n",
    "    Args:\n",
    "        text: Input string.\n",
    "\n",
    "    Returns:\n",
    "        True if text starts with V-DO grammar structure, False otherwise.\n",
    "\n",
    "    Notes:\n",
    "        * Only the first sentence is considered.\n",
    "        * Since past forms (e.g. fixed) and gerunds (e.g. fixing) are often not tagged as verbs,\n",
    "          there is an extra preprocessing step: lemmatization of first word if it is a verb.\n",
    "        * Current implementation supports not only Direct Objects consisting of single noun,\n",
    "          but also clauses/phrases.\n",
    "    \"\"\"\n",
    "    first_word = text.split(\" \")[0]\n",
    "    processed_first_word = spacy_nlp(first_word)[0]\n",
    "    if processed_first_word.pos_ == \"VERB\":\n",
    "        text = \" \".join([processed_first_word.lemma_] + text.split(\" \")[1:])\n",
    "\n",
    "    doc = spacy_nlp(text)\n",
    "\n",
    "    token = doc[0]\n",
    "    if (\n",
    "        token.pos_ == \"VERB\"\n",
    "        and token.dep_ == \"ROOT\"\n",
    "        and len([t.dep_ for t in token.children])\n",
    "        and [t.dep_ for t in token.children][0] == \"dobj\"\n",
    "    ):\n",
    "        return True\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:36:37.001486Z",
     "end_time": "2023-04-18T17:36:38.750471Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sanity checks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Firstly, there are examples where V-DO filter doesn't work as intended. Consider this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`update readme` wasn't marked as V-DO\n",
      "`update file` wasn't marked as V-DO\n"
     ]
    }
   ],
   "source": [
    "for text in [\"update gif\", \"update readme\", \"update file\", \"update something\"]:\n",
    "    if not is_verb_direct_object(text):\n",
    "        print(f\"`{text}` wasn't marked as V-DO\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:36:39.369645Z",
     "end_time": "2023-04-18T17:36:39.418046Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For some reasons, sometimes `update ...` sentence is not marked as V-DO, while with other nouns it works fine."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next sanity check is running our implementation on Jiang et al.'s V-DO filtered dataset. Specifically, we use its further filtered version from [Neural-machine-translation-based commit message generation: how far are we?](https://dl.acm.org/doi/10.1145/3238147.3238190), ASE 2018."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:16:30.196219Z",
     "end_time": "2023-04-18T17:16:30.571054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-18 17:16:30--  https://raw.githubusercontent.com/Tbabm/nngen/master/data/cleaned.test.msg\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 100151 (98K) [text/plain]\r\n",
      "Saving to: ‘cleaned.test.msg’\r\n",
      "\r\n",
      "cleaned.test.msg    100%[===================>]  97.80K  --.-KB/s    in 0.02s   \r\n",
      "\r\n",
      "2023-04-18 17:16:30 (4.55 MB/s) - ‘cleaned.test.msg’ saved [100151/100151]\r\n",
      "\r\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/Tbabm/nngen/master/data/cleaned.test.msg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:36:41.087967Z",
     "end_time": "2023-04-18T17:36:41.696162Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2521it [00:14, 174.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "non_vdo = []\n",
    "vdo = []\n",
    "with open(\"cleaned.test.msg\", \"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        if not is_verb_direct_object(line.strip()):\n",
    "            non_vdo.append(line)\n",
    "        else:\n",
    "            vdo.append(line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:36:42.083168Z",
     "end_time": "2023-04-18T17:36:56.529400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(1688, 833)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vdo), len(non_vdo)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:36:56.530724Z",
     "end_time": "2023-04-18T17:36:56.534422Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Around 2/3 examples get marked as V-DO by current implementation."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:18:31.389179Z",
     "end_time": "2023-04-18T17:18:45.109448Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2521it [00:13, 183.78it/s]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here are some examples that got marked as V-DO:"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:18:45.108812Z",
     "end_time": "2023-04-18T17:18:45.112224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1688, 833)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fix snapshot version \\n',\n",
      " 'update chagelog \\n',\n",
      " 'Added joscar JAR . \\n',\n",
      " 'Fix TsExtractor tests \\n',\n",
      " 'bump engine . io - client \\n',\n",
      " 'Remove observer only if it has been registered \\n',\n",
      " 'Fix typo in README . md \\n',\n",
      " 'prepare release checkstyle - 7 . 1 . 1 \\n',\n",
      " 'Updated the version string to the version of T4J \\n',\n",
      " 'update h2o - flow version to 0 . 5 . 0 with . . . ( # 684 ) \\n',\n",
      " 'Updated webchat logo - added oracle logo as a separate image \\n',\n",
      " 'Removed non - needed imports \\n',\n",
      " 'Add missing link to the 2 . 0 migration guide . \\n',\n",
      " 'setting version to 1 . 0 . 133 - SNAPSHOT \\n',\n",
      " 'remove classpath from manifest \\n',\n",
      " 'Put that coffee down . \\n',\n",
      " 'Create Protocol - Overview . \\n',\n",
      " 'Make NOPASS . \\n',\n",
      " 'Fix test data so that it can be compiled \\n',\n",
      " 'Add notifications package index . \\n']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(vdo[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:36:56.534180Z",
     "end_time": "2023-04-18T17:36:56.536649Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here are some examples that didn't get marked as V-DO:"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:16:45.676532Z",
     "end_time": "2023-04-18T17:16:45.678561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fix snapshot version \\n',\n",
      " 'update chagelog \\n',\n",
      " 'Added joscar JAR . \\n',\n",
      " 'Fix TsExtractor tests \\n',\n",
      " 'bump engine . io - client \\n',\n",
      " 'Remove observer only if it has been registered \\n',\n",
      " 'Fix typo in README . md \\n',\n",
      " 'prepare release checkstyle - 7 . 1 . 1 \\n',\n",
      " 'Updated the version string to the version of T4J \\n',\n",
      " 'update h2o - flow version to 0 . 5 . 0 with . . . ( # 684 ) \\n',\n",
      " 'Updated webchat logo - added oracle logo as a separate image \\n',\n",
      " 'Removed non - needed imports \\n',\n",
      " 'Add missing link to the 2 . 0 migration guide . \\n',\n",
      " 'setting version to 1 . 0 . 133 - SNAPSHOT \\n',\n",
      " 'remove classpath from manifest \\n',\n",
      " 'Put that coffee down . \\n',\n",
      " 'Create Protocol - Overview . \\n',\n",
      " 'Make NOPASS . \\n',\n",
      " 'Fix test data so that it can be compiled \\n',\n",
      " 'Add notifications package index . \\n']\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edit coverage colors icon \\n',\n",
      " 'LRQA - 14419 Add new property to turn on running tests with poshi runner \\n',\n",
      " 'moving tools . jar inside the jre \\n',\n",
      " 'Call close ( ) instead of deactivate ( ) in CursorToBulkCursorAdaptor . '\n",
      " 'close ( ) \\n',\n",
      " 'missed shift \\n',\n",
      " 'Ignore files generated by the sharpen process \\n',\n",
      " 'Revert \" Added Circle CI configuration \" \\n',\n",
      " 'LRQA - 17074 Modify java . jdk . type property from x64 to x32 \\n',\n",
      " 'update fonts \\n',\n",
      " 'Ignore time - zone data \\n',\n",
      " 'Updated jar \\n',\n",
      " 'Set min width for add dialog . \\n',\n",
      " 'Fix bug 558 , PImage . save ( ) method not working with get ( ) \\n',\n",
      " 'Ninja - add debug log statement to mv builder scheduled at startup \\n',\n",
      " 'bump up druid version to 0 . 4 . 0 \\n',\n",
      " 'JAL - 39 Add image for propietary license \\n',\n",
      " 'Change default fbo cache size to 0 \\n',\n",
      " 'LPS - 48807 Remove EOL \\n',\n",
      " 'prepare for next development iteration \\n',\n",
      " 'Fixes a crash of the QTKit video CaptureDevice on Snow Leopard reported by '\n",
      " 'Yana Stamcheva . \\n']\n"
     ]
    }
   ],
   "source": [
    "pprint(non_vdo[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:36:56.538120Z",
     "end_time": "2023-04-18T17:36:56.541689Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prefixes like `LRQA - 14419` definitely do not fall under current V-DO implementation. I wonder if they were cleared in original dataset?\n",
    "\n",
    "And again, there are some false negatives."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:16:45.679502Z",
     "end_time": "2023-04-18T17:16:45.685924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edit coverage colors icon \\n',\n",
      " 'LRQA - 14419 Add new property to turn on running tests with poshi runner \\n',\n",
      " 'moving tools . jar inside the jre \\n',\n",
      " 'Call close ( ) instead of deactivate ( ) in CursorToBulkCursorAdaptor . '\n",
      " 'close ( ) \\n',\n",
      " 'missed shift \\n',\n",
      " 'Ignore files generated by the sharpen process \\n',\n",
      " 'Revert \" Added Circle CI configuration \" \\n',\n",
      " 'LRQA - 17074 Modify java . jdk . type property from x64 to x32 \\n',\n",
      " 'update fonts \\n',\n",
      " 'Ignore time - zone data \\n',\n",
      " 'Updated jar \\n',\n",
      " 'Set min width for add dialog . \\n',\n",
      " 'Fix bug 558 , PImage . save ( ) method not working with get ( ) \\n',\n",
      " 'Ninja - add debug log statement to mv builder scheduled at startup \\n',\n",
      " 'bump up druid version to 0 . 4 . 0 \\n',\n",
      " 'JAL - 39 Add image for propietary license \\n',\n",
      " 'Change default fbo cache size to 0 \\n',\n",
      " 'LPS - 48807 Remove EOL \\n',\n",
      " 'prepare for next development iteration \\n',\n",
      " 'Fixes a crash of the QTKit video CaptureDevice on Snow Leopard reported by '\n",
      " 'Yana Stamcheva . \\n']\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stanza implementation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:18:45.114494Z",
     "end_time": "2023-04-18T17:18:45.117497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edit coverage colors icon \\n',\n",
      " 'LRQA - 14419 Add new property to turn on running tests with poshi runner \\n',\n",
      " 'moving tools . jar inside the jre \\n',\n",
      " 'Call close ( ) instead of deactivate ( ) in CursorToBulkCursorAdaptor . '\n",
      " 'close ( ) \\n',\n",
      " 'missed shift \\n',\n",
      " 'Ignore files generated by the sharpen process \\n',\n",
      " 'Revert \" Added Circle CI configuration \" \\n',\n",
      " 'LRQA - 17074 Modify java . jdk . type property from x64 to x32 \\n',\n",
      " 'update fonts \\n',\n",
      " 'Ignore time - zone data \\n',\n",
      " 'Updated jar \\n',\n",
      " 'Set min width for add dialog . \\n',\n",
      " 'Fix bug 558 , PImage . save ( ) method not working with get ( ) \\n',\n",
      " 'Ninja - add debug log statement to mv builder scheduled at startup \\n',\n",
      " 'bump up druid version to 0 . 4 . 0 \\n',\n",
      " 'JAL - 39 Add image for propietary license \\n',\n",
      " 'Change default fbo cache size to 0 \\n',\n",
      " 'LPS - 48807 Remove EOL \\n',\n",
      " 'prepare for next development iteration \\n',\n",
      " 'Fixes a crash of the QTKit video CaptureDevice on Snow Leopard reported by '\n",
      " 'Yana Stamcheva . \\n']\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also considered an implementation via Python analogue of [CoreNLP](https://github.com/stanfordnlp/CoreNLP) – [Stanza](https://github.com/stanfordnlp/stanza). It also provides Python wrappers over some of CoreNLP's features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import stanza\n",
    "\n",
    "\n",
    "stanza.download(\"en\")\n",
    "stanza_nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize,lemma,pos,depparse\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:38:27.928903Z",
     "end_time": "2023-04-18T17:38:34.868113Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def stanza_is_verb_direct_object(text: str) -> bool:\n",
    "    \"\"\"Implements filter by Verb-Direct Object grammar structure via Stanza package.\n",
    "\n",
    "    Args:\n",
    "        text: Input string.\n",
    "\n",
    "    Returns:\n",
    "        True if text starts with V-DO grammar structure, False otherwise.\n",
    "\n",
    "    Notes:\n",
    "        * Only the first sentence is considered.\n",
    "        * Since past forms (e.g. fixed) and gerunds (e.g. fixing) are often not tagged as verbs,\n",
    "          there is an extra preprocessing step: lemmatization of first word if it is a verb.\n",
    "        * Current implementation supports not only Direct Objects consisting of single noun,\n",
    "          but also clauses/phrases.\n",
    "    \"\"\"\n",
    "    # lemmatize first word if it's a verb\n",
    "    first_word = text.split(\" \")[0]\n",
    "    processed_first_word = stanza_nlp(first_word).sentences[0].words[0]\n",
    "    if processed_first_word.upos == \"VERB\":\n",
    "        text = \" \".join([processed_first_word.lemma] + text.split(\" \")[1:])\n",
    "\n",
    "    # run stanza pipeline\n",
    "    processed_text = stanza_nlp(text)\n",
    "    first_sent = processed_text.sentences[0]\n",
    "\n",
    "    # check: first word is a verb and there is a word that relates to it as `obj`\n",
    "    # `dobj` -> `obj`: https://github.com/stanfordnlp/stanza/issues/936\n",
    "    first_word = first_sent.words[0]\n",
    "    if first_word.upos == \"VERB\":\n",
    "        for word in first_sent.words[1:]:\n",
    "            if word.deprel == \"obj\" and word.head == first_word.id:\n",
    "                return True\n",
    "\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:38:34.871794Z",
     "end_time": "2023-04-18T17:38:34.873335Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sanity checks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:20:12.201889Z",
     "end_time": "2023-04-18T17:20:28.777271Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Stanza` implementation suffer from the same issue as `spaCy` one:"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:20:45.823643Z",
     "end_time": "2023-04-18T17:20:45.839508Z"
    }
   },
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`update gif` wasn't marked as V-DO\n",
      "`update readme` wasn't marked as V-DO\n",
      "`update file` wasn't marked as V-DO\n"
     ]
    }
   ],
   "source": [
    "for text in [\"update gif\", \"update readme\", \"update file\"]:\n",
    "    if not stanza_is_verb_direct_object(text):\n",
    "        print(f\"`{text}` wasn't marked as V-DO\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:38:34.875135Z",
     "end_time": "2023-04-18T17:38:35.256647Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, the check on the Jiang et al.'s dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2521it [06:59,  6.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "non_vdo = []\n",
    "vdo = []\n",
    "with open(\"cleaned.test.msg\", \"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        if not stanza_is_verb_direct_object(line.strip()):\n",
    "            non_vdo.append(line)\n",
    "        else:\n",
    "            vdo.append(line)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:38:41.837764Z",
     "end_time": "2023-04-18T17:45:41.782153Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(1965, 556)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vdo), len(non_vdo)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:45:41.782800Z",
     "end_time": "2023-04-18T17:45:41.785771Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can observe that `Stanza` implementation marked more sentences as V-DO than `spaCy` one. However, the processing speed is way lower. Running it on our ~10M examples would require substantial resources.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:21:07.447099Z",
     "end_time": "2023-04-18T17:28:07.115606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2521it [06:59,  6.01it/s]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here are some examples that got marked as V-DO:"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:28:07.113914Z",
     "end_time": "2023-04-18T17:28:07.127011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1965, 556)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fix snapshot version \\n',\n",
      " 'Added joscar JAR . \\n',\n",
      " 'Fix TsExtractor tests \\n',\n",
      " 'moving tools . jar inside the jre \\n',\n",
      " 'Remove observer only if it has been registered \\n',\n",
      " 'Fix typo in README . md \\n',\n",
      " 'prepare release checkstyle - 7 . 1 . 1 \\n',\n",
      " 'Updated the version string to the version of T4J \\n',\n",
      " 'update h2o - flow version to 0 . 5 . 0 with . . . ( # 684 ) \\n',\n",
      " 'missed shift \\n',\n",
      " 'Updated webchat logo - added oracle logo as a separate image \\n',\n",
      " 'Ignore files generated by the sharpen process \\n',\n",
      " 'Removed non - needed imports \\n',\n",
      " 'Add missing link to the 2 . 0 migration guide . \\n',\n",
      " 'setting version to 1 . 0 . 133 - SNAPSHOT \\n',\n",
      " 'Revert \" Added Circle CI configuration \" \\n',\n",
      " 'remove classpath from manifest \\n',\n",
      " 'Put that coffee down . \\n',\n",
      " 'Create Protocol - Overview . \\n',\n",
      " 'Make NOPASS . \\n']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "pprint(vdo[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:45:41.785430Z",
     "end_time": "2023-04-18T17:45:41.789528Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here are some examples that didn't get marked as V-DO:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['update chagelog \\n',\n",
      " 'edit coverage colors icon \\n',\n",
      " 'LRQA - 14419 Add new property to turn on running tests with poshi runner \\n',\n",
      " 'bump engine . io - client \\n',\n",
      " 'Call close ( ) instead of deactivate ( ) in CursorToBulkCursorAdaptor . '\n",
      " 'close ( ) \\n',\n",
      " 'LRQA - 17074 Modify java . jdk . type property from x64 to x32 \\n',\n",
      " 'update fonts \\n',\n",
      " 'Update the changelog file \\n',\n",
      " 'Prepare 3 . 0 . 0 release \\n',\n",
      " 'Updated jar \\n',\n",
      " 'update support annotations to 23 . 0 . 1 \\n',\n",
      " 'Ninja - add debug log statement to mv builder scheduled at startup \\n',\n",
      " 'updated examples \\n',\n",
      " 'JAL - 39 Add image for propietary license \\n',\n",
      " 'update linux - x86 natives \\n',\n",
      " 'LPS - 48807 Remove EOL \\n',\n",
      " 'prepare for next development iteration \\n',\n",
      " 'updated todo . txt \\n',\n",
      " 'Update SpongeCommon for DestructEntityEvent cause fix . \\n',\n",
      " 'Update build tools \\n']\n"
     ]
    }
   ],
   "source": [
    "pprint(non_vdo[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:45:41.789101Z",
     "end_time": "2023-04-18T17:45:41.792813Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter by length\n",
    "\n",
    "Many datasets set strict restrictions for maximum number of tokens both for diffs and for messages. The most frequent filters are:\n",
    "\n",
    "* Maximum length for messages: up to 30 tokens\n",
    "* Maximum length for diffs: up to 100 tokens\n",
    "\n",
    "Our implementation performs tokenization on whitespaces and punctuation."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T17:28:07.127292Z",
     "end_time": "2023-04-18T17:28:07.176253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['update chagelog \\n',\n",
      " 'edit coverage colors icon \\n',\n",
      " 'LRQA - 14419 Add new property to turn on running tests with poshi runner \\n',\n",
      " 'bump engine . io - client \\n',\n",
      " 'Call close ( ) instead of deactivate ( ) in CursorToBulkCursorAdaptor . '\n",
      " 'close ( ) \\n',\n",
      " 'LRQA - 17074 Modify java . jdk . type property from x64 to x32 \\n',\n",
      " 'update fonts \\n',\n",
      " 'Update the changelog file \\n',\n",
      " 'Prepare 3 . 0 . 0 release \\n',\n",
      " 'Updated jar \\n',\n",
      " 'update support annotations to 23 . 0 . 1 \\n',\n",
      " 'Ninja - add debug log statement to mv builder scheduled at startup \\n',\n",
      " 'updated examples \\n',\n",
      " 'JAL - 39 Add image for propietary license \\n',\n",
      " 'update linux - x86 natives \\n',\n",
      " 'LPS - 48807 Remove EOL \\n',\n",
      " 'prepare for next development iteration \\n',\n",
      " 'updated todo . txt \\n',\n",
      " 'Update SpongeCommon for DestructEntityEvent cause fix . \\n',\n",
      " 'Update build tools \\n']\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from nltk import wordpunct_tokenize\n",
    "\n",
    "\n",
    "def is_shorter_than_n_tokens(text: str, n: int) -> bool:\n",
    "    num_tokens = len(wordpunct_tokenize(text))\n",
    "    return num_tokens <= n\n",
    "\n",
    "\n",
    "def is_longer_than_n_tokens(text: str, n: int) -> bool:\n",
    "    num_tokens = len(wordpunct_tokenize(text))\n",
    "    return num_tokens >= n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# #2: Results on MCMD dataset\n",
    "\n",
    "In this section, we provide the statistics for all the filters for [MCMD dataset](https://github.com/DeepSoftwareAnalytics/CommitMsgEmpirical) from [On the Evaluation of Commit Message Generation Models: An Experimental Study](https://arxiv.org/abs/2107.05373v3), ICSME 2021."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading MCMD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MCMD contains 5 PLs:\n",
    "* C#\n",
    "* C++\n",
    "* Java\n",
    "* JavaScript\n",
    "* Python\n",
    "\n",
    "Examples for every language are stored in its own folder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "['csharp',\n 'cpp',\n 'directoryList.md',\n 'java',\n 'javascript',\n 'mcmd.tar.gz',\n 'csharp-vdo_results.txt',\n 'python']"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "['csharp',\n 'javascript-vdo_results.txt',\n 'cpp',\n 'directoryList.md',\n 'java',\n 'cpp-vdo_results.txt',\n 'java-vdo_results.txt',\n 'javascript',\n 'mcmd.tar.gz',\n 'csharp-vdo_results.txt',\n 'python-vdo_results.txt',\n 'python']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/home/ubuntu/datasets/mcmd\")\n",
    "os.listdir()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For each language, there are two train/val/test splits available: random and by time. Let's choose random (it shouldn't matter for us anyway)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['valid.jsonl',\n 'train.jsonl',\n 'sort_time_train80_valid10_test10',\n 'test.jsonl',\n 'sort_random_train80_valid10_test10']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = [\"csharp\", \"cpp\", \"java\", \"javascript\", \"python\"]\n",
    "os.listdir(\"cpp\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we have a bunch of .txt files with prefixes `train`/`valid`/`test`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "['train.time.txt',\n 'train.diff.txt',\n 'train.msg.txt',\n 'train.sha.txt',\n 'train.repo.txt']"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fname for fname in os.listdir(\"cpp/sort_random_train80_valid10_test10\") if fname.startswith(\"train\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's refactor it to JSONLines."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csharp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360000it [01:14, 4835.34it/s]\n",
      "45000it [00:08, 5410.84it/s]\n",
      "45000it [00:11, 3785.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360000it [01:07, 5308.37it/s]\n",
      "45000it [00:07, 6417.79it/s]\n",
      "45000it [00:07, 6267.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360000it [01:13, 4895.36it/s]\n",
      "45000it [00:07, 6105.76it/s]\n",
      "45000it [00:07, 6186.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javascript\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360000it [01:12, 4937.30it/s]\n",
      "45000it [00:07, 5872.50it/s]\n",
      "45000it [00:07, 5706.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360000it [00:51, 6997.75it/s]\n",
      "45000it [00:06, 7210.69it/s]\n",
      "45000it [00:05, 8402.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "\n",
    "split = \"sort_random_train80_valid10_test10\"\n",
    "\n",
    "for lang in langs:\n",
    "    print(lang)\n",
    "    for part in [\"train\", \"valid\", \"test\"]:\n",
    "        with open(f\"{lang}/{split}/{part}.diff.txt\", \"r\") as diff_file:\n",
    "            with open(f\"{lang}/{split}/{part}.time.txt\", \"r\") as time_file:\n",
    "                with open(f\"{lang}/{split}/{part}.msg.txt\", \"r\") as msg_file:\n",
    "                    with open(f\"{lang}/{split}/{part}.sha.txt\", \"r\") as sha_file:\n",
    "                        with open(f\"{lang}/{split}/{part}.repo.txt\", \"r\") as repo_file:\n",
    "                            for diff_line, time_line, msg_line, sha_line, repo_line in tqdm(\n",
    "                                zip(diff_file, time_file, msg_file, sha_file, repo_file)\n",
    "                            ):\n",
    "                                cur_example = {\n",
    "                                    \"diff\": diff_line.strip(),\n",
    "                                    \"time\": time_line.strip(),\n",
    "                                    \"msg\": msg_line.strip(),\n",
    "                                    \"sha\": sha_line.strip(),\n",
    "                                    \"repo\": repo_line.strip(),\n",
    "                                }\n",
    "                                with jsonlines.open(f\"{lang}/{part}.jsonl\", \"a\") as writer:\n",
    "                                    writer.write(cur_example)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First sentence filter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "first_sentence_stats_newline = defaultdict(list)\n",
    "first_sentence_stats_punct = defaultdict(list)\n",
    "\n",
    "for lang in langs:\n",
    "    print(lang)\n",
    "    for part in [\"train\", \"valid\", \"test\"]:\n",
    "        with jsonlines.open(f\"{lang}/{part}.jsonl\", \"r\") as reader:\n",
    "            for line in tqdm(reader):\n",
    "                first_sentence_stats_newline[lang].append(is_one_sentence(line[\"msg\"], mode=\"newline\"))\n",
    "                first_sentence_stats_punct[lang].append(is_one_sentence(line[\"msg\"], mode=\"punct\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### Newline results\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All commit messages in MCMD contain only one newline character."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "      csharp     cpp    java  javascript  python\nTrue  450000  450000  450000      450000  450000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>csharp</th>\n      <th>cpp</th>\n      <th>java</th>\n      <th>javascript</th>\n      <th>python</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>True</th>\n      <td>450000</td>\n      <td>450000</td>\n      <td>450000</td>\n      <td>450000</td>\n      <td>450000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "first_sentence_stats_newline_df = pd.DataFrame(first_sentence_stats_newline)\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        col: first_sentence_stats_newline_df[col].value_counts(dropna=False)\n",
    "        for col in first_sentence_stats_newline_df.columns\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Punctuation results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we split sentences via NLTK's `sent_tokenize`, the results are slightly different.\n",
    "\n",
    "* There are cases which lead to errors and result in `None`. It's mostly messages that start with punctuation, e.g. `.gitignore`.\n",
    "* The majority of the message still have only one sentence, but there are many messages that contain more than one."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "       csharp     cpp    java  javascript  python\nTrue   332004  384304  379252      361640  357084\nFalse  117844   62037   70685       88222   92805\nNaN       152    3659      63         138     111",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>csharp</th>\n      <th>cpp</th>\n      <th>java</th>\n      <th>javascript</th>\n      <th>python</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>True</th>\n      <td>332004</td>\n      <td>384304</td>\n      <td>379252</td>\n      <td>361640</td>\n      <td>357084</td>\n    </tr>\n    <tr>\n      <th>False</th>\n      <td>117844</td>\n      <td>62037</td>\n      <td>70685</td>\n      <td>88222</td>\n      <td>92805</td>\n    </tr>\n    <tr>\n      <th>NaN</th>\n      <td>152</td>\n      <td>3659</td>\n      <td>63</td>\n      <td>138</td>\n      <td>111</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_sentence_stats_punct_df = pd.DataFrame(first_sentence_stats_punct)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        col: first_sentence_stats_punct_df[col].value_counts(dropna=False)\n",
    "        for col in first_sentence_stats_punct_df.columns\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Verb-Direct Object filter (spaCy)\n",
    "\n",
    "> Note: calculating V-DO filters takes substantial time, hence, we launched spaCy implementation outside of this notebook and just read the results here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csharp\n",
      "cpp\n",
      "java\n",
      "javascript\n",
      "python\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "\n",
    "\n",
    "vdo_results = {}\n",
    "\n",
    "for lang in langs:\n",
    "    print(lang)\n",
    "    with jsonlines.open(f\"{lang}-vdo_results.txt\", \"r\") as reader:\n",
    "        vdo_results[lang] = [line[\"is_vdo\"] for line in reader]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "       csharp     cpp    java  javascript  python\nFalse  261411  268477  287488      262456  278572\nTrue   188589  181523  162512      187544  171428",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>csharp</th>\n      <th>cpp</th>\n      <th>java</th>\n      <th>javascript</th>\n      <th>python</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>False</th>\n      <td>261411</td>\n      <td>268477</td>\n      <td>287488</td>\n      <td>262456</td>\n      <td>278572</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>188589</td>\n      <td>181523</td>\n      <td>162512</td>\n      <td>187544</td>\n      <td>171428</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "vdo_results_df = pd.DataFrame(vdo_results)\n",
    "\n",
    "pd.DataFrame({col: vdo_results_df[col].value_counts(dropna=False) for col in vdo_results_df.columns})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filters by length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "msg_30_tokens_stats = defaultdict(list)\n",
    "diff_100_tokens_stats = defaultdict(list)\n",
    "\n",
    "for lang in langs:\n",
    "    print(lang)\n",
    "    for part in [\"train\", \"valid\", \"test\"]:\n",
    "        with jsonlines.open(f\"{lang}/{part}.jsonl\", \"r\") as reader:\n",
    "            for line in tqdm(reader):\n",
    "                msg_30_tokens_stats[lang].append(is_shorter_than_n_tokens(line[\"msg\"], 30))\n",
    "                diff_100_tokens_stats[lang].append(is_shorter_than_n_tokens(line[\"diff\"], 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Messages $\\leq 30$ tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "       csharp     cpp    java  javascript  python\nTrue   447119  446226  445136      447633  448432\nFalse    2881    3774    4864        2367    1568",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>csharp</th>\n      <th>cpp</th>\n      <th>java</th>\n      <th>javascript</th>\n      <th>python</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>True</th>\n      <td>447119</td>\n      <td>446226</td>\n      <td>445136</td>\n      <td>447633</td>\n      <td>448432</td>\n    </tr>\n    <tr>\n      <th>False</th>\n      <td>2881</td>\n      <td>3774</td>\n      <td>4864</td>\n      <td>2367</td>\n      <td>1568</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_30_tokens_stats_df = pd.DataFrame(msg_30_tokens_stats)\n",
    "\n",
    "pd.DataFrame({col: msg_30_tokens_stats_df[col].value_counts(dropna=False) for col in msg_30_tokens_stats_df.columns})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Diffs $\\leq 100$ tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "       csharp     cpp    java  javascript  python\nFalse  435151  434381  442333      433322  431063\nTrue    14849   15619    7667       16678   18937",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>csharp</th>\n      <th>cpp</th>\n      <th>java</th>\n      <th>javascript</th>\n      <th>python</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>False</th>\n      <td>435151</td>\n      <td>434381</td>\n      <td>442333</td>\n      <td>433322</td>\n      <td>431063</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>14849</td>\n      <td>15619</td>\n      <td>7667</td>\n      <td>16678</td>\n      <td>18937</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_100_tokens_stats_df = pd.DataFrame(diff_100_tokens_stats)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {col: diff_100_tokens_stats_df[col].value_counts(dropna=False) for col in diff_100_tokens_stats_df.columns}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# #3: Results on our dataset\n",
    "\n",
    "In this section, we provide the statistics for all the filters for our dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading our dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['train.jsonl', 'val.jsonl', 'test.jsonl']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "[fname for fname in os.listdir(\"extracted_data_jsonl/dataset\") if \".jsonl\" in fname]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First sentence filter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7659458it [07:18, 17465.31it/s]\n",
      "1554042it [01:29, 17420.63it/s]\n",
      "1486267it [01:25, 17382.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "first_sentence_stats_newline = defaultdict(list)\n",
    "first_sentence_stats_punct = defaultdict(list)\n",
    "\n",
    "for part in [\"train\", \"val\", \"test\"]:\n",
    "    with jsonlines.open(f\"extracted_data_jsonl/dataset/{part}.jsonl\", \"r\") as reader:\n",
    "        for line in tqdm(reader):\n",
    "            first_sentence_stats_newline[line[\"language\"]].append(is_one_sentence(line[\"message\"], mode=\"newline\"))\n",
    "            first_sentence_stats_punct[line[\"language\"]].append(is_one_sentence(line[\"message\"], mode=\"punct\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Newline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       TypeScript     PHP  JavaScript   Python     Java      Go    Ruby  \\\nTrue      1144948  215706     1282665  1520334  1087622  721721  198778   \nFalse      167279   31761      193434   269805   269437  218977   56483   \n\n           C#     C++       C   Swift  Kotlin  Smalltalk   Shell    Rust  \\\nTrue   505687  916163  294733  125758  160606      11297  132736  277624   \nFalse   70191  239961  110730   12681   51472       1418   26112   68368   \n\n        Dart  Groovy  Objective-C    Nix  Elixir  \nTrue   48344   50226        32360  76954   43007  \nFalse  14139   13580         9159  19702    7809  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TypeScript</th>\n      <th>PHP</th>\n      <th>JavaScript</th>\n      <th>Python</th>\n      <th>Java</th>\n      <th>Go</th>\n      <th>Ruby</th>\n      <th>C#</th>\n      <th>C++</th>\n      <th>C</th>\n      <th>Swift</th>\n      <th>Kotlin</th>\n      <th>Smalltalk</th>\n      <th>Shell</th>\n      <th>Rust</th>\n      <th>Dart</th>\n      <th>Groovy</th>\n      <th>Objective-C</th>\n      <th>Nix</th>\n      <th>Elixir</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>True</th>\n      <td>1144948</td>\n      <td>215706</td>\n      <td>1282665</td>\n      <td>1520334</td>\n      <td>1087622</td>\n      <td>721721</td>\n      <td>198778</td>\n      <td>505687</td>\n      <td>916163</td>\n      <td>294733</td>\n      <td>125758</td>\n      <td>160606</td>\n      <td>11297</td>\n      <td>132736</td>\n      <td>277624</td>\n      <td>48344</td>\n      <td>50226</td>\n      <td>32360</td>\n      <td>76954</td>\n      <td>43007</td>\n    </tr>\n    <tr>\n      <th>False</th>\n      <td>167279</td>\n      <td>31761</td>\n      <td>193434</td>\n      <td>269805</td>\n      <td>269437</td>\n      <td>218977</td>\n      <td>56483</td>\n      <td>70191</td>\n      <td>239961</td>\n      <td>110730</td>\n      <td>12681</td>\n      <td>51472</td>\n      <td>1418</td>\n      <td>26112</td>\n      <td>68368</td>\n      <td>14139</td>\n      <td>13580</td>\n      <td>9159</td>\n      <td>19702</td>\n      <td>7809</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "\n",
    "d = {}\n",
    "for key in first_sentence_stats_newline:\n",
    "    d[key] = pd.Series(first_sentence_stats_newline[key]).value_counts(dropna=False)\n",
    "pd.DataFrame(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Punctuation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "       TypeScript     PHP  JavaScript   Python     Java      Go    Ruby  \\\nTrue      1254224  232260     1402237  1650513  1227838  853374  231586   \nFalse       57997   13534       73852   139623   129162   87319   23674   \n\n           C#      C++       C   Swift  Kotlin  Smalltalk   Shell    Rust  \\\nTrue   540853  1019984  350205  131502  189802      11512  149606  314693   \nFalse   35015   136113   55256    6936   22272       1190    9242   31297   \n\n        Dart  Groovy  Objective-C    Nix  Elixir  \nTrue   54195   59358        36796  90407   48097  \nFalse   8288    4448         4723   6249    2719  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TypeScript</th>\n      <th>PHP</th>\n      <th>JavaScript</th>\n      <th>Python</th>\n      <th>Java</th>\n      <th>Go</th>\n      <th>Ruby</th>\n      <th>C#</th>\n      <th>C++</th>\n      <th>C</th>\n      <th>Swift</th>\n      <th>Kotlin</th>\n      <th>Smalltalk</th>\n      <th>Shell</th>\n      <th>Rust</th>\n      <th>Dart</th>\n      <th>Groovy</th>\n      <th>Objective-C</th>\n      <th>Nix</th>\n      <th>Elixir</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>True</th>\n      <td>1254224</td>\n      <td>232260</td>\n      <td>1402237</td>\n      <td>1650513</td>\n      <td>1227838</td>\n      <td>853374</td>\n      <td>231586</td>\n      <td>540853</td>\n      <td>1019984</td>\n      <td>350205</td>\n      <td>131502</td>\n      <td>189802</td>\n      <td>11512</td>\n      <td>149606</td>\n      <td>314693</td>\n      <td>54195</td>\n      <td>59358</td>\n      <td>36796</td>\n      <td>90407</td>\n      <td>48097</td>\n    </tr>\n    <tr>\n      <th>False</th>\n      <td>57997</td>\n      <td>13534</td>\n      <td>73852</td>\n      <td>139623</td>\n      <td>129162</td>\n      <td>87319</td>\n      <td>23674</td>\n      <td>35015</td>\n      <td>136113</td>\n      <td>55256</td>\n      <td>6936</td>\n      <td>22272</td>\n      <td>1190</td>\n      <td>9242</td>\n      <td>31297</td>\n      <td>8288</td>\n      <td>4448</td>\n      <td>4723</td>\n      <td>6249</td>\n      <td>2719</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "d = {}\n",
    "for key in first_sentence_stats_punct:\n",
    "    d[key] = pd.Series(first_sentence_stats_punct[key]).value_counts(dropna=True)\n",
    "pd.DataFrame(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Verb-Direct Object filter (spaCy)\n",
    "\n",
    "> Note: calculating V-DO filters takes substantial time, hence, we launched spaCy implementation outside of this notebook and just read the results here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7659458it [04:46, 26763.29it/s]\n",
      "1554042it [00:56, 27287.71it/s]\n",
      "1486267it [00:55, 26952.20it/s]\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "vdo_stats = defaultdict(list)\n",
    "\n",
    "for part in [\"train\", \"val\", \"test\"]:\n",
    "    with jsonlines.open(f\"extracted_data_jsonl/dataset/{part}.jsonl\", \"r\") as reader:\n",
    "        with jsonlines.open(f\"stats/{part}_vdo_results.jsonl\", \"r\") as reader2:\n",
    "            for (line, line2) in tqdm(zip(reader, reader2)):\n",
    "                assert line[\"hash\"] == line2[\"hash\"]\n",
    "                assert line[\"repo\"] == line2[\"repo\"]\n",
    "                vdo_stats[line[\"language\"]].append(line2[\"is_vdo\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "       TypeScript     PHP  JavaScript   Python    Java      Go    Ruby  \\\nFalse      922809  147978      957241  1063093  841861  611725  146161   \nTrue       389418   99489      518858   727046  515198  328973  109100   \n\n           C#     C++       C  Swift  Kotlin  Smalltalk   Shell    Rust  \\\nFalse  332002  726941  295762  77681  130585       7613  101955  224065   \nTrue   243876  429183  109701  60758   81493       5102   56893  121927   \n\n        Dart  Groovy  Objective-C    Nix  Elixir  \nFalse  40704   36392        24366  93496   30437  \nTrue   21779   27414        17153   3160   20379  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TypeScript</th>\n      <th>PHP</th>\n      <th>JavaScript</th>\n      <th>Python</th>\n      <th>Java</th>\n      <th>Go</th>\n      <th>Ruby</th>\n      <th>C#</th>\n      <th>C++</th>\n      <th>C</th>\n      <th>Swift</th>\n      <th>Kotlin</th>\n      <th>Smalltalk</th>\n      <th>Shell</th>\n      <th>Rust</th>\n      <th>Dart</th>\n      <th>Groovy</th>\n      <th>Objective-C</th>\n      <th>Nix</th>\n      <th>Elixir</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>False</th>\n      <td>922809</td>\n      <td>147978</td>\n      <td>957241</td>\n      <td>1063093</td>\n      <td>841861</td>\n      <td>611725</td>\n      <td>146161</td>\n      <td>332002</td>\n      <td>726941</td>\n      <td>295762</td>\n      <td>77681</td>\n      <td>130585</td>\n      <td>7613</td>\n      <td>101955</td>\n      <td>224065</td>\n      <td>40704</td>\n      <td>36392</td>\n      <td>24366</td>\n      <td>93496</td>\n      <td>30437</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>389418</td>\n      <td>99489</td>\n      <td>518858</td>\n      <td>727046</td>\n      <td>515198</td>\n      <td>328973</td>\n      <td>109100</td>\n      <td>243876</td>\n      <td>429183</td>\n      <td>109701</td>\n      <td>60758</td>\n      <td>81493</td>\n      <td>5102</td>\n      <td>56893</td>\n      <td>121927</td>\n      <td>21779</td>\n      <td>27414</td>\n      <td>17153</td>\n      <td>3160</td>\n      <td>20379</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "d = {}\n",
    "for key in vdo_stats:\n",
    "    d[key] = pd.Series(vdo_stats[key]).value_counts(dropna=True)\n",
    "pd.DataFrame(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filters by length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7659458it [47:00, 2715.41it/s] \n",
      "1554042it [09:07, 2837.44it/s]\n",
      "1486267it [08:56, 2768.68it/s]\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "msg_30_tokens_stats = defaultdict(list)\n",
    "diff_100_tokens_stats = defaultdict(list)\n",
    "diff_200_tokens_stats = defaultdict(list)\n",
    "\n",
    "for part in [\"train\", \"val\", \"test\"]:\n",
    "    with jsonlines.open(f\"extracted_data_jsonl/dataset/{part}.jsonl\", \"r\") as reader:\n",
    "        for line in tqdm(reader):\n",
    "            msg_30_tokens_stats[line[\"language\"]].append(is_shorter_than_n_tokens(line[\"message\"], n=30))\n",
    "            diff = \"\\n\".join([mod[\"diff\"] for mod in line[\"mods\"]])\n",
    "            diff_100_tokens_stats[line[\"language\"]].append(is_shorter_than_n_tokens(diff, n=100))\n",
    "            diff_200_tokens_stats[line[\"language\"]].append(is_shorter_than_n_tokens(diff, n=200))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Messages $\\leq 30$ tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "       TypeScript     PHP  JavaScript   Python     Java      Go    Ruby  \\\nTrue      1260106  238345     1409254  1685767  1265843  850580  232404   \nFalse       52121    9122       66845   104372    91216   90118   22857   \n\n           C#      C++       C   Swift  Kotlin  Smalltalk   Shell    Rust  \\\nTrue   551919  1050542  357632  134048  193499      12284  148936  318359   \nFalse   23959   105582   47831    4391   18579        431    9912   27633   \n\n        Dart  Groovy  Objective-C    Nix  Elixir  \nTrue   57910   59133        38200  89164   48425  \nFalse   4573    4673         3319   7492    2391  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TypeScript</th>\n      <th>PHP</th>\n      <th>JavaScript</th>\n      <th>Python</th>\n      <th>Java</th>\n      <th>Go</th>\n      <th>Ruby</th>\n      <th>C#</th>\n      <th>C++</th>\n      <th>C</th>\n      <th>Swift</th>\n      <th>Kotlin</th>\n      <th>Smalltalk</th>\n      <th>Shell</th>\n      <th>Rust</th>\n      <th>Dart</th>\n      <th>Groovy</th>\n      <th>Objective-C</th>\n      <th>Nix</th>\n      <th>Elixir</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>True</th>\n      <td>1260106</td>\n      <td>238345</td>\n      <td>1409254</td>\n      <td>1685767</td>\n      <td>1265843</td>\n      <td>850580</td>\n      <td>232404</td>\n      <td>551919</td>\n      <td>1050542</td>\n      <td>357632</td>\n      <td>134048</td>\n      <td>193499</td>\n      <td>12284</td>\n      <td>148936</td>\n      <td>318359</td>\n      <td>57910</td>\n      <td>59133</td>\n      <td>38200</td>\n      <td>89164</td>\n      <td>48425</td>\n    </tr>\n    <tr>\n      <th>False</th>\n      <td>52121</td>\n      <td>9122</td>\n      <td>66845</td>\n      <td>104372</td>\n      <td>91216</td>\n      <td>90118</td>\n      <td>22857</td>\n      <td>23959</td>\n      <td>105582</td>\n      <td>47831</td>\n      <td>4391</td>\n      <td>18579</td>\n      <td>431</td>\n      <td>9912</td>\n      <td>27633</td>\n      <td>4573</td>\n      <td>4673</td>\n      <td>3319</td>\n      <td>7492</td>\n      <td>2391</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "d = {}\n",
    "for key in msg_30_tokens_stats:\n",
    "    d[key] = pd.Series(msg_30_tokens_stats[key]).value_counts(dropna=True)\n",
    "pd.DataFrame(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Diffs $\\leq 100$ tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "       TypeScript     PHP  JavaScript   Python     Java      Go    Ruby  \\\nFalse     1104200  200322     1221080  1486622  1190731  824444  203682   \nTrue       208027   47145      255019   303517   166328  116254   51579   \n\n           C#     C++       C   Swift  Kotlin  Smalltalk   Shell    Rust  \\\nFalse  482360  992511  330870  115939  184206      10090  130438  305556   \nTrue    93518  163613   74593   22500   27872       2625   28410   40436   \n\n        Dart  Groovy  Objective-C    Nix  Elixir  \nFalse  54220   53700        33936  59973   42831  \nTrue    8263   10106         7583  36683    7985  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TypeScript</th>\n      <th>PHP</th>\n      <th>JavaScript</th>\n      <th>Python</th>\n      <th>Java</th>\n      <th>Go</th>\n      <th>Ruby</th>\n      <th>C#</th>\n      <th>C++</th>\n      <th>C</th>\n      <th>Swift</th>\n      <th>Kotlin</th>\n      <th>Smalltalk</th>\n      <th>Shell</th>\n      <th>Rust</th>\n      <th>Dart</th>\n      <th>Groovy</th>\n      <th>Objective-C</th>\n      <th>Nix</th>\n      <th>Elixir</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>False</th>\n      <td>1104200</td>\n      <td>200322</td>\n      <td>1221080</td>\n      <td>1486622</td>\n      <td>1190731</td>\n      <td>824444</td>\n      <td>203682</td>\n      <td>482360</td>\n      <td>992511</td>\n      <td>330870</td>\n      <td>115939</td>\n      <td>184206</td>\n      <td>10090</td>\n      <td>130438</td>\n      <td>305556</td>\n      <td>54220</td>\n      <td>53700</td>\n      <td>33936</td>\n      <td>59973</td>\n      <td>42831</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>208027</td>\n      <td>47145</td>\n      <td>255019</td>\n      <td>303517</td>\n      <td>166328</td>\n      <td>116254</td>\n      <td>51579</td>\n      <td>93518</td>\n      <td>163613</td>\n      <td>74593</td>\n      <td>22500</td>\n      <td>27872</td>\n      <td>2625</td>\n      <td>28410</td>\n      <td>40436</td>\n      <td>8263</td>\n      <td>10106</td>\n      <td>7583</td>\n      <td>36683</td>\n      <td>7985</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "d = {}\n",
    "for key in diff_100_tokens_stats:\n",
    "    d[key] = pd.Series(diff_100_tokens_stats[key]).value_counts(dropna=True)\n",
    "pd.DataFrame(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# #4: Saving filters results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We identified the following filters as the most frequent:\n",
    "\n",
    "* First Sentence\n",
    "* V-DO\n",
    "* Message Length $\\leq 30$ tokens\n",
    "* Diff Length $\\leq 100$ tokens\n",
    "\n",
    "We want to run some experiments and compare the results with filtered and unfiltered subsets. This section provides an utility script for saving filters results for each commit from our dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from typing import Dict, Union\n",
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def process_example(example: Dict[str, str]) -> Dict[str, Union[str, bool]]:\n",
    "    return {\n",
    "        \"hash\": example[\"hash\"],\n",
    "        \"repo\": example[\"repo\"],\n",
    "        \"is_vdo\": example[\"is_vdo\"],\n",
    "        \"first_sentence_newline\": is_one_sentence(example[\"message\"], mode=\"newline\"),\n",
    "        \"first_sentence_punct\": is_one_sentence(example[\"message\"], mode=\"punct\"),\n",
    "        \"message_30_tokens\": is_shorter_than_n_tokens(example[\"message\"], n=30),\n",
    "        \"diff_100_tokens\": is_shorter_than_n_tokens(example[\"diff\"], n=100),\n",
    "    }\n",
    "\n",
    "\n",
    "chunksize = 4000\n",
    "\n",
    "\n",
    "for part in [\"train\", \"val\", \"test\"]:\n",
    "    output_path = f\"stats/filters_{part}.jsonl\"\n",
    "    open(output_path, \"w\").close()\n",
    "\n",
    "    chunk = []\n",
    "    with jsonlines.open(f\"extracted_data_jsonl/dataset/{part}.jsonl\", \"r\") as reader:\n",
    "        with jsonlines.open(f\"stats/{part}_vdo_results.jsonl\", \"r\") as reader2:\n",
    "            for (dataset_example, vdo_example) in tqdm(zip(reader, reader2), desc=f\"Processing filters for {part}\"):\n",
    "                assert dataset_example[\"hash\"] == vdo_example[\"hash\"]\n",
    "                assert dataset_example[\"repo\"] == vdo_example[\"repo\"]\n",
    "\n",
    "                if len(chunk) > chunksize:\n",
    "                    with Parallel(16) as pool:\n",
    "                        processed_chunk = pool(delayed(process_example)(example) for example in chunk)\n",
    "                    with jsonlines.open(output_path, \"a\") as writer:\n",
    "                        writer.write_all(processed_chunk)\n",
    "                    chunk = []\n",
    "\n",
    "                chunk.append(\n",
    "                    {\n",
    "                        \"hash\": dataset_example[\"hash\"],\n",
    "                        \"repo\": dataset_example[\"repo\"],\n",
    "                        \"is_vdo\": vdo_example[\"is_vdo\"],\n",
    "                        \"message\": dataset_example[\"message\"],\n",
    "                        \"diff\": \"\\n\".join([mod[\"diff\"] for mod in dataset_example[\"mods\"]]),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            if len(chunk) > 0:\n",
    "                with Parallel(16) as pool:\n",
    "                    processed_chunk = pool(delayed(process_example)(example) for example in chunk)\n",
    "                with jsonlines.open(output_path, \"a\") as writer:\n",
    "                    writer.write_all(processed_chunk)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
