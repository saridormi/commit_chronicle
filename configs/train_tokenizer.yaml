data_format: jsonl
line_sep: "[NL]"
msg_tokens: false

diff_extractor:
  chunksize: 32000
  n_workers: 16

tokenizer:
  configuration: byte_level

  byte_level:
    tokenizer:
      dropout: 0.5

    train:
      vocab_size: 32000
      min_frequency: 3

  custom:
    tokenizer:
      _target_: tokenizers.models.BPE
      dropout: 0.5

    normalizer: false

    pre_tokenizer:
      _target_: tokenizers.pre_tokenizers.Whitespace

    decoder: false

    trainer:
      _convert_: all
      _target_: tokenizers.trainers.BpeTrainer
      special_tokens:
      vocab_size: 32000
      min_frequency: 3

paths:
  input_dir: extracted_data_jsonl/filtered_diffs
  tokenizer_dir: tokenizer