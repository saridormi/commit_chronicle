data_format: jsonl
line_sep: "[NL]"

training_processor:
  chunksize: 4096

  diff_tokenizer_name_or_path:
  msg_tokenizer_name_or_path:

  diff_kwargs:
    truncation: false
    add_special_tokens: false
    return_attention_mask: false

  msg_kwargs:
    truncation: false
    add_special_tokens: false
    return_attention_mask: false

only_messages: false
only_diffs: false

preprocess_data: true
tokenize_data: true
truncate_diffs: true
context_len: 512

paths:
  input_dir: extracted_data_jsonl/lexed
  output_dir: processed_data/byte_level
  temp_dir: processed_data/byte_level
  diff_tokenizer_name_or_path: tokenizer/byte_level/transformers_format
  msg_tokenizer_name_or_path: tokenizer/byte_level/transformers_format

